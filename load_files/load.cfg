#!/bin/bash

# Copyright 2019 ThoughtSpot
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation
# files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy,
# modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT
# OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

# This file defines all of the settings for running a single load from a directory (and optionally sub-directories) using the
# load_files bash script.  You should be able to modify this file and use with load_file with no additonal modification.

# NOTE that the variables below are generally assumed to exist.  Deleting a variable rather than simply changing the value may
# cause errors in the load script.

# -----------------------------------------------------------------------------------------------------------------------------------------
# GENERAL SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# General settings, such as the file system loaded on
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -r SOURCE_TYPE="file_system"                      # can be one of "file_system" or "aws_s3".  Default is "file_system".
#declare -r SOURCE_TYPE="aws_s3"                          # can be one of "file_system" or "aws_s3".  Default is "file_system".

# -----------------------------------------------------------------------------------------------------------------------------------------
# AWS S3 SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# Settings specific for AWS S3 loads. If using AWS S3 as a source, set these flags.  The DATA_DIR from above will not 
# √çbe used and you should use the AWS_S3_DATA_DIR instead.
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -r AWS_S3_ACCESS_KEY_ID=""
declare -r AWS_S3_SECRET_ACCESS_KEY=""
declare -r AWS_S3_REGION="us-west-1"                      # regions here:  https://docs.aws.amazon.com/general/latest/gr/rande.html
declare -r AWS_S3_BUCKET="<source_bucket_name>"           # name of the bucket for files to load.
declare -r AWS_S3_ARCHIVE_BUCKET="<archive_bucket_name>"  # name of the bucket to save loaded files.  If blank no archive (and also no 
                                                          #archive dir) will happen.
declare -r AWS_S3_DATA_DIR="/"                            # folder under the bucket to start loading from.  This is the actual data root.
declare -r AWS_S3_ARCHIVE_DIR=""                          # folder under the bucket to archive data to
declare -r AWS_S3_BUF_CAPACITY=134217728                  # buffer for loading files

# -----------------------------------------------------------------------------------------------------------------------------------------
# FOLDER SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# Locations of scripts, data, archive and log files, folders to ignore etc
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -r ROOT_DIR="/home/admin"                         # Root where files for loading are located.
declare -r LOG_DIR=${ROOT_DIR}/logs                       # directory to store load logs.
declare -r IGNORE_DIRS=(dont_load test old)               # list of directories to ignore files to load.

if [[ ${SOURCE_TYPE} == "file_system" ]]; then            # FILE SYSTEM ONLY:
  declare -r DATA_DIR=${ROOT_DIR}/data                    # location for the data to load.  Write files to load here.
  declare -r OLD_DIR_ROOT=${ROOT_DIR}/old                 # the 'root' folder for the old_dir (only used for clean-up)
fi
if [[ ${SOURCE_TYPE} == "aws_s3" ]]; then                 # AWS ONLY: if we have a archive bucket, use that. If there is also 
                                                          # an archive folder, append that to the archive location. If
                                                          # there is only an archive folder, the original bucket will be used with
                                                          # that archive folder
  ARCHIVE_LOCATION=""
  if [[ ${AWS_S3_ARCHIVE_BUCKET} != "" ]]; then
    declare ARCHIVE_LOCATION="${AWS_S3_ARCHIVE_BUCKET}"
    if [[ ${AWS_S3_ARCHIVE_DIR} != "" ]]; then
      ARCHIVE_LOCATION="${ARCHIVE_LOCATION}${AWS_S3_ARCHIVE_DIR}"
    fi
  elif [[ ${AWS_S3_ARCHIVE_DIR} != "" ]]; then
    declare ARCHIVE_LOCATION="${AWS_S3_BUCKET}${AWS_S3_ARCHIVE_DIR}"
  fi

  declare OLD_DIR_ROOT="s3://${ARCHIVE_LOCATION}" # root location for copying loaded files.
  OLD_DIR_ROOT="${OLD_DIR_ROOT%/}"
fi

# -----------------------------------------------------------------------------------------------------------------------------------------
# FILE SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# Which files to include and exclude and operations to be execute on file and filename
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -r DATA_FILE_EXTENSION=".csv"                     # extension for files to be loaded.
declare -r EXCLUDE_PATTERN="_del.csv"                     # pattern which should be excluded in the files matched using the 
                                                          # DATA_FILE_EXTENSION
declare -r SED_PATTERNS=("_0.*" "and_me")                 # Set any parts of the names that will be stripped from the file name to 
                                                          # determine the table name. Patters separated by spaces.
declare -r RUN_DOS2UNIX=0                                 # If set to 1, the load process will run a dos2unix on the input file before 
                                                          # loading it (does not work with S3)

# -----------------------------------------------------------------------------------------------------------------------------------------
# ARCHIVE SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# Defines how input and log files are archived at the end of the process
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -r MOVE_LOADED_FILES="mv"                         # Command for files that were loaded.  Either "mv" or "cp" or "echo".
declare -r NBR_DAYS_TO_KEEP_OLD_FILES=7                   # must be integer, set to blank to not remove old archives.
declare -r ARCHIVE_DATA="always"                          # Whether the data should be archived in the old folder.
                                                          # For large data sets this can take considerable time and space. Valid options:
                                                          # - always     : Files are always archived, tarred etc
                                                          # - onsuccess  : Files are only archived when processed successfully (others stay 
                                                          #                in the source folder)
                                                          # - onerror    : Files are archived when one of the files in the load failed
                                                          # - onbad      : Files are archived when one of the files generated bad records
                                                          # - never      : Files are never archived

# -----------------------------------------------------------------------------------------------------------------------------------------
# EMAIL SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# Settings for the results email which is sent at the end of the loading process
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -r RESULTS_EMAIL=("user.name@company.com")        # email addresses to send the results to.
declare -r USE_HTML_EMAIL=1                               # flag (0=false, 1=true) whether to send email in html format

# -----------------------------------------------------------------------------------------------------------------------------------------
# DATABASE SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# Target location settings, such as database and default schema name
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -r DATABASE_NAME="my_db"                          # database name.  Only one currently support per config.
declare -r DEFAULT_SCHEMA_NAME="falcon_default_schema"    # default schema name.

# -----------------------------------------------------------------------------------------------------------------------------------------
# LOAD SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# Generic load settings such as the semaphore file name to wait for or the truncate option when multi-part files are used
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -r SEMAPHORE_FILE_NAME="stage_done"               # name of a file that indicates all staging files are loaded. 
                                                          # if using a semaphore file to control the start, set it here.  
                                                          # Set to "" if not using.

declare -r TRUNCATE_BEFORE_LOAD="false"                   # If "true", tables will be truncated when first loaded.  Useful if table input
                                                          # files are delivered in parts

# -----------------------------------------------------------------------------------------------------------------------------------------
# TSLOAD settings.
# -----------------------------------------------------------------------------------------------------------------------------------------
# TODO set the flags for your environment.  The assumption is that all files have the same format.  If you have different
# formats, consider multiple configuration files and loads.
# -----------------------------------------------------------------------------------------------------------------------------------------
#declare -r DEFAULT_EMPTY_TARGET="--empty_target"         # either --empty_target or ""
declare -r DEFAULT_EMPTY_TARGET=""                        # either --empty_target or ""
declare -r SOURCE_DATA_FORMAT=csv                         # either csv or delimited.
declare -r FIELD_SEPARATOR="|"                            # field separator in the data.
declare -r MAX_IGNORED_ROWS=0                             # maximum rows to ignore.  0 recommended for production.
declare -r HAS_HEADER_ROW="true"                          # true if there is a header row to ignore.
declare -r NULL_VALUE=""                                  # value in the data for NULLs
declare -r DATE_FORMAT="%d-%m-%Y"                         # format for parsing dates
declare -r DATE_TIME_FORMAT="%d-%m-%Y %I.%M.%S %p %Z"     # format for parsing date/times
declare -r TIME_FORMAT="%H:%M:%S"                         # format for parsing times
declare -r BOOLEAN_REPRESENTATION="True_False"            # Boolean representation as True_False
declare -r FORMAT_FILE_DIR="${ROOT_DIR}/format"           # Location of format files for tables, leave empty if not used                        

# -----------------------------------------------------------------------------------------------------------------------------------------
# PRE/POST SHELL SCRIPTS SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# Shell scripts to load before loading a table
# NOTE: If you specify @LOAD as the table name then this script will be execute at the beginning or end of the complete process
#
# Note that for each script by default the following parameters are passed to it, additional parameters can be added in the array
#   -d|--database DATABASE_NAME   Name of the database where the table resides
#   -s|--schema   SCHEMA_NAME     Name of the schema where the table resides
#   -t|--table    TABLE_NAME      Name of the table to execute a delete for
#   -c|--config   CONFIG_FILE     Name of the config file used in the load process
#   -l|--log      LOG_FILE        Name of the log file to write logging messages to
#   -f|--file     SOURCE_FILE     The souce file being loaded
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -A pre_load_shell=()                              # Shell script to run before the specified table is loaded
# declare -A pre_load_shell=(
#        ["@LOAD"]="bash ${ROOT_DIR]/bin/my_script.sh "
#        ["the_table"]="bash ${ROOT_DIR]/bin/my_script.sh "
# )
declare -A post_load_shell=()                             # Shell script to run after the specified table is loaded
# declare -A post_load_shell=(
#        ["@LOAD"]="bash ${ROOT_DIR]/bin/my_script.sh "
#        ["the_table"]="bash ${ROOT_DIR}/bin/my_script.sh"
# )

declare -r SCRIPT_MAX_CHECK_ATTEMPTS=10                   # If a script was not completed, but returned to shell (timeout)
                                                          # how many times it should keep on checking before failing
declare -r SCRIPT_CHECK_WAIT_TIME=1                       # Time in seconds to wait in between attempts

# -----------------------------------------------------------------------------------------------------------------------------------------
# PRE/POST TQL COMMANDS SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# TQL to run before or after loading a table
# NOTE: If you specify @LOAD as the table name then this script will be execute at the beginning or end of the complete process
#
# -----------------------------------------------------------------------------------------------------------------------------------------
archive_date=$(date --date="7 days ago" +%Y-%m-%d)
declare -A pre_load_tql=()                                # TQL Command to run before a table is loaded
#declare -A pre_load_tql=(
#        ["@LOAD"]="delete from the_table where date_id>='$archive_date'"
#        ["the_table"]="delete from the_table where date_id>='$archive_date'"
#)

# TQL to run after loading a table
declare -A post_load_tql=()                               # TQL Command to run after a table is loaded
#declare -A post_load_tql=(
#        ["@LOAD"]="show table the_table;"
#        ["the_table"]="show table the_table;"
#)

# -----------------------------------------------------------------------------------------------------------------------------------------
# GENERATE EXTRA (DEFAULT) COLUMNS HEADERS
# -----------------------------------------------------------------------------------------------------------------------------------------
# The following two "extra_table" sections allow you to specify extra columns to add to the data when doing file_system loads.
# This capability is helpful for scenarios where you want to provide default values for columns that are not in the data.
# Currently the data is hard coded.  Update each section for the tables you want to add.
# -----------------------------------------------------------------------------------------------------------------------------------------
declare -A extra_table_headers=()                         # Defines a mapping of table names to additional headers to add.  
                                                          # Should match extra_table_values() below
# declare -A extra_table_headers=(
#   ["test_table1"]="new_column1"
#   ["test_table2"]="new_column2${FIELD_SEPARATOR}new_column3"
# )

declare -A extra_table_values=()                          # Defines a mapping of table names to additional values to add.  
                                                          # Should match extra_table_headers() above
# declare -A extra_table_values=(
#   ["test_table1"]="new_value1"
#   ["test_table2"]="new_value2${FIELD_SEPARATOR}new_value3"
# )

# -----------------------------------------------------------------------------------------------------------------------------------------
# INTERNAL SETTINGS
# -----------------------------------------------------------------------------------------------------------------------------------------
# The following can be modified, but typically don't need to be.
# -----------------------------------------------------------------------------------------------------------------------------------------
# Get the cluster name for cluster specific logging.
if hash tscli 2>/dev/null; then
  declare -r CLUSTER_NAME="$(tscli cluster status | grep 'Cluster name' | sed 's/^.*: //' | sed 's/ /_/')"
else
  declare -r CLUSTER_NAME="no_cluster_on_$(hostname -s)"
fi

declare -r THE_DATE_TIME="$(date +"%Y-%m-%d_%H%M%S_%Z")"                            # date and time to use for load name.
declare -r TEMP_TSLOAD_FILE="/tmp/$$.tsload.out"                                    # temp file for capturing tsload output per file
declare -r TEMP_RESULTS_FILE="/tmp/$$.results"                                      # temp file for detailed results.
declare -r TEMP_STATS_FILE="/tmp/$$.tsload_stats.txt"                               # temp file for loading stats.
declare -r TEMP_RESULTS_SUMMARY_FILE="/tmp/$$.results.summary"                      # temp folder for results summary.
declare -r RESULTS_FILE="${LOG_DIR}/${CLUSTER_NAME}-results-${THE_DATE_TIME}.txt"   # stores the results of the data load.
declare -r LOADING_FILE="${ROOT_DIR}/loading"                                       # flag to indicate we are currently loading.
declare -r V_LEVEL=0                                                                # logging verbosity level.  0-6.  
                                                                                    # 0 recommended for production.
declare -r OLD_DIR="${OLD_DIR_ROOT}/${THE_DATE_TIME}"                               # directory to store loaded files and bad records to. 
                                                                                    # This just adds the timestamp to the folder already defined






